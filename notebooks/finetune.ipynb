{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db9c7f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\richa\\Documents\\GitHub\\transformers-interpret\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "print(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1028a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset cadec (C:\\Users\\richa\\.cache\\huggingface\\datasets\\cadec\\cadec_bigbio_kb\\1.0.0\\aa0c4972a66d4e69245748c72bda714effb7d8c98aea405f186dd03cb488dbb0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69c4a939f9434017b4833aeaf7fe07e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from bigbio.dataloader import BigBioConfigHelpers\n",
    "conhelps = BigBioConfigHelpers()\n",
    "dataset_name = 'cadec_bigbio_kb'\n",
    "dataset = conhelps.for_config_name(dataset_name).load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ff7ee96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9843f30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import load_dataset\n",
    "\n",
    "# dataset = load_dataset(\"yelp_review_full\")\n",
    "\n",
    "# dataset[\"train\"][100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c361e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoModelForTokenClassification, TokenClassificationPipeline, AutoConfig\n",
    "huggingface_model = 'dslim/bert-base-NER'\n",
    "tokenizer: AutoTokenizer = AutoTokenizer.from_pretrained(huggingface_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ed00539",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'O': 0, 'ADR': 1, 'Disease': 2, 'Drug': 3, 'Finding': 4, 'Symptom': 5}\n"
     ]
    }
   ],
   "source": [
    "from transformers_interpret.evaluation.input_pre_processor import InputPreProcessor, get_labels_from_dataset\n",
    "label2id, id2label = get_labels_from_dataset(dataset)\n",
    "print(label2id)\n",
    "pre_processor = InputPreProcessor(tokenizer, label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a85d022f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dslim/bert-base-NER and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([9, 768]) in the checkpoint and torch.Size([6, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([9]) in the checkpoint and torch.Size([6]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model: AutoModelForTokenClassification = AutoModelForTokenClassification.from_pretrained(huggingface_model, ignore_mismatched_sizes=True, num_labels=len(label2id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aec861b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for split in dataset:\n",
    "#     empty_documents = []\n",
    "#     print(len(dataset[split]))\n",
    "#     for i, doc in enumerate(dataset[split]):\n",
    "#         doc = doc | pre_processor(doc)\n",
    "#         print(doc)\n",
    "#         break\n",
    "#         if len(doc['text']) == 0:\n",
    "#             empty_documents.append(i)\n",
    "#     dataset[split] = dataset[split].select([i for i in range(len(dataset[split])) if i not in empty_documents])\n",
    "#     print(len(dataset[split]))\n",
    "#     dataset[split].feature = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8649c7b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function tokenize_function at 0x00000215AA6CB4C0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b358b25b32984f2ebf36e82cabcda001",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1250 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at C:\\Users\\richa\\.cache\\huggingface\\datasets\\cadec\\cadec_bigbio_kb\\1.0.0\\aa0c4972a66d4e69245748c72bda714effb7d8c98aea405f186dd03cb488dbb0\\cache-04b4a739e075869a.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['id', 'document_id', 'passages', 'entities', 'events', 'coreferences', 'relations', 'text', 'labels', 'input_ids', 'token_type_ids', 'attention_mask', 'offset_mapping'],\n",
      "    num_rows: 625\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    return pre_processor(examples)\n",
    "#     return tokenizer(passages, padding=\"max_length\", truncation=True)  # [\"passages\"][0][0]\n",
    "\n",
    "dataset_length = len(dataset[\"train\"])\n",
    "tokenized_datasets = dataset.map(tokenize_function)\n",
    "train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(dataset_length//2))\n",
    "eval_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(dataset_length//2, dataset_length))\n",
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "829685cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '593', 'document_id': 'LIPITOR.48', 'passages': [{'id': 'LIPITOR.48__text', 'type': 'abstract', 'text': ['Stopped because of HIGH CPK.\\nMy Liver blood test are also mildly elevated.\\nI was in deniel that the statins would cause ME side effects- I have Terrible muscle and joint pain, Burning sensations in neck shoulders and upper chest.\\nPalpatations .\\nInsomnia because can not sleep from pain.\\nI do not want to take pain killers all the time since they have side effects too.\\nWeight gain -probably not associated.\\nIOne of the reasons I left my job is because I was so weak all the time and had difficulty walking and driving.\\nI was a Sales rep for a drug company and many years ago I promoted Zocor.\\nHow IRONIC that I should suffer from statins my self.\\nMy life is miserable.\\nI feel like dying.\\nI am sorry I did not keep my weight low so as to avoid my lipids to go so high.\\nThat way I would have never had to suffer like I am now.\\nThe doctors just say and my husband OH your in pain because you are over weight.\\nThe doctors also did not even follow me up properly.\\nWHo can I sue??????\\nThat is the question.\\n'], 'offsets': [[0, 1001]]}], 'entities': [{'id': 'LIPITOR.48_T1', 'type': 'ADR', 'text': ['HIGH CPK'], 'offsets': [[19, 27]], 'normalized': [{'db_name': 'Meddra', 'db_id': '10011368'}, {'db_name': 'Snomed CT', 'db_id': '432352001'}]}, {'id': 'LIPITOR.48_T2', 'type': 'ADR', 'text': ['Liver blood test', 'mildly elevated'], 'offsets': [[32, 48], [58, 73]], 'normalized': [{'db_name': 'Meddra', 'db_id': '10048556'}, {'db_name': 'Snomed CT', 'db_id': '67251005'}]}, {'id': 'LIPITOR.48_T3', 'type': 'ADR', 'text': ['muscle', 'pain'], 'offsets': [[153, 159], [170, 174]], 'normalized': [{'db_name': 'Meddra', 'db_id': '10028411'}, {'db_name': 'Snomed CT', 'db_id': '68962001'}]}, {'id': 'LIPITOR.48_T4', 'type': 'ADR', 'text': ['joint', 'pain'], 'offsets': [[164, 169], [170, 174]], 'normalized': [{'db_name': 'Meddra', 'db_id': '10003239'}, {'db_name': 'Snomed CT', 'db_id': '57676002'}]}, {'id': 'LIPITOR.48_T6', 'type': 'ADR', 'text': ['Burning sensations in', 'shoulders'], 'offsets': [[176, 197], [203, 212]], 'normalized': [{'db_name': 'Meddra', 'db_id': '10006784'}, {'db_name': 'Snomed CT', 'db_id': '90673000'}]}, {'id': 'LIPITOR.48_T7', 'type': 'ADR', 'text': ['Burning sensations in', 'upper chest'], 'offsets': [[176, 197], [217, 228]], 'normalized': [{'db_name': 'Meddra', 'db_id': '10006785'}, {'db_name': 'Snomed CT', 'db_id': '90673000'}]}, {'id': 'LIPITOR.48_T5', 'type': 'ADR', 'text': ['Burning sensations in', 'neck'], 'offsets': [[176, 197], [198, 202]], 'normalized': [{'db_name': 'Meddra', 'db_id': '10006786'}, {'db_name': 'Snomed CT', 'db_id': '90673000'}]}, {'id': 'LIPITOR.48_T8', 'type': 'ADR', 'text': ['Palpatations'], 'offsets': [[230, 242]], 'normalized': [{'db_name': 'Meddra', 'db_id': '10033557'}, {'db_name': 'Snomed CT', 'db_id': '80313002'}]}, {'id': 'LIPITOR.48_T9', 'type': 'ADR', 'text': ['Insomnia'], 'offsets': [[245, 253]], 'normalized': [{'db_name': 'Meddra', 'db_id': '10022437'}, {'db_name': 'Snomed CT', 'db_id': '193462001'}]}, {'id': 'LIPITOR.48_T10', 'type': 'ADR', 'text': ['Weight gain'], 'offsets': [[369, 380]], 'normalized': [{'db_name': 'Meddra', 'db_id': '10047896'}, {'db_name': 'Snomed CT', 'db_id': '8943002'}]}, {'id': 'LIPITOR.48_T11', 'type': 'ADR', 'text': ['weak all the time'], 'offsets': [[461, 478]], 'normalized': [{'db_name': 'Meddra', 'db_id': '10003549'}, {'db_name': 'Snomed CT', 'db_id': '13791008'}]}, {'id': 'LIPITOR.48_T12', 'type': 'ADR', 'text': ['difficulty walking'], 'offsets': [[487, 505]], 'normalized': [{'db_name': 'Meddra', 'db_id': '10047810'}, {'db_name': 'Snomed CT', 'db_id': '228158008'}]}, {'id': 'LIPITOR.48_T13', 'type': 'Drug', 'text': ['Zocor'], 'offsets': [[586, 591]], 'normalized': [{'db_name': 'Snomed CT', 'db_id': '3904011000036106'}]}, {'id': 'LIPITOR.48_T14', 'type': 'ADR', 'text': ['pain'], 'offsets': [[872, 876]], 'normalized': [{'db_name': 'Meddra', 'db_id': '10033371'}, {'db_name': 'Snomed CT', 'db_id': '22253000'}]}, {'id': 'LIPITOR.48_T15', 'type': 'Disease', 'text': ['over weight'], 'offsets': [[893, 904]], 'normalized': [{'db_name': 'Snomed CT', 'db_id': '238131007'}]}], 'events': [], 'coreferences': [], 'relations': [], 'text': 'Stopped because of HIGH CPK. \\nMy Liver blood test are also mildly elevated. \\nI was in deniel that the statins would cause ME side effects- I have Terrible muscle and joint pain, Burning sensations in neck shoulders and upper chest. \\nPalpatations . \\nInsomnia because can not sleep from pain. \\nI do not want to take pain killers all the time since they have side effects too. \\nWeight gain -probably not associated. \\nIOne of the reasons I left my job is because I was so weak all the time and had difficulty walking and driving. \\nI was a Sales rep for a drug company and many years ago I promoted Zocor.\\nHow IRONIC that I should suffer from statins my self. \\nMy life is miserable. \\nI feel like dying. \\nI am sorry I did not keep my weight low so as to avoid my lipids to go so high. \\nThat way I would have never had to suffer like I am now. \\nThe doctors just say and my husband OH your in pain because you are over weight. \\nThe doctors also did not even follow me up properly. \\nWHo can I sue?????? \\nThat is the question. \\n', 'labels': [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'input_ids': [101, 6682, 3537, 1272, 1104, 145, 23413, 3048, 20360, 2428, 119, 1422, 3374, 1197, 1892, 2774, 1132, 1145, 21461, 8208, 119, 146, 1108, 1107, 10552, 10387, 1115, 1103, 188, 19756, 4935, 1156, 2612, 22157, 1334, 3154, 118, 146, 1138, 12008, 27788, 6484, 1105, 4091, 2489, 117, 17807, 24783, 1107, 2455, 3221, 1105, 3105, 2229, 119, 19585, 1233, 4163, 18837, 119, 1130, 7301, 1306, 5813, 1272, 1169, 1136, 2946, 1121, 2489, 119, 146, 1202, 1136, 1328, 1106, 1321, 2489, 21870, 1155, 1103, 1159, 1290, 1152, 1138, 1334, 3154, 1315, 119, 25589, 4361, 118, 1930, 1136, 2628, 119, 146, 2346, 1673, 1104, 1103, 3672, 146, 1286, 1139, 2261, 1110, 1272, 146, 1108, 1177, 4780, 1155, 1103, 1159, 1105, 1125, 7262, 3179, 1105, 3759, 119, 146, 1108, 170, 15689, 1231, 1643, 1111, 170, 3850, 1419, 1105, 1242, 1201, 2403, 146, 3082, 163, 13335, 1766, 119, 1731, 146, 21564, 27451, 1658, 1115, 146, 1431, 8813, 1121, 188, 19756, 4935, 1139, 2191, 119, 1422, 1297, 1110, 14531, 119, 146, 1631, 1176, 5694, 119, 146, 1821, 2959, 146, 1225, 1136, 1712, 1139, 2841, 1822, 1177, 1112, 1106, 3644, 1139, 4764, 7540, 1106, 1301, 1177, 1344, 119, 1337, 1236, 146, 1156, 1138, 1309, 1125, 1106, 8813, 1176, 146, 1821, 1208, 119, 1109, 8114, 1198, 1474, 1105, 1139, 2252, 18719, 1240, 1107, 2489, 1272, 1128, 1132, 1166, 2841, 119, 1109, 8114, 1145, 1225, 1136, 1256, 2812, 1143, 1146, 7513, 119, 160, 3048, 1186, 1169, 146, 25762, 136, 136, 136, 136, 136, 136, 1337, 1110, 1103, 2304, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'offset_mapping': [[0, 0], [0, 4], [4, 7], [8, 15], [16, 18], [19, 20], [20, 22], [22, 23], [24, 26], [26, 27], [27, 28], [30, 32], [33, 37], [37, 38], [39, 44], [45, 49], [50, 53], [54, 58], [59, 65], [66, 74], [74, 75], [77, 78], [79, 82], [83, 85], [86, 89], [89, 92], [93, 97], [98, 101], [102, 103], [103, 106], [106, 109], [110, 115], [116, 121], [122, 124], [125, 129], [130, 137], [137, 138], [139, 140], [141, 145], [146, 148], [148, 154], [155, 161], [162, 165], [166, 171], [172, 176], [176, 177], [178, 185], [186, 196], [197, 199], [200, 204], [205, 214], [215, 218], [219, 224], [225, 230], [230, 231], [233, 235], [235, 236], [236, 238], [238, 245], [246, 247], [249, 251], [251, 253], [253, 254], [254, 257], [258, 265], [266, 269], [270, 273], [274, 279], [280, 284], [285, 289], [289, 290], [292, 293], [294, 296], [297, 300], [301, 305], [306, 308], [309, 313], [314, 318], [319, 326], [327, 330], [331, 334], [335, 339], [340, 345], [346, 350], [351, 355], [356, 360], [361, 368], [369, 372], [372, 373], [375, 381], [382, 386], [387, 388], [388, 396], [397, 400], [401, 411], [411, 412], [414, 415], [415, 416], [416, 418], [419, 421], [422, 425], [426, 433], [434, 435], [436, 440], [441, 443], [444, 447], [448, 450], [451, 458], [459, 460], [461, 464], [465, 467], [468, 472], [473, 476], [477, 480], [481, 485], [486, 489], [490, 493], [494, 504], [505, 512], [513, 516], [517, 524], [524, 525], [527, 528], [529, 532], [533, 534], [535, 540], [541, 543], [543, 544], [545, 548], [549, 550], [551, 555], [556, 563], [564, 567], [568, 572], [573, 578], [579, 582], [583, 584], [585, 593], [594, 595], [595, 597], [597, 599], [599, 600], [601, 604], [605, 606], [606, 608], [608, 610], [610, 611], [612, 616], [617, 618], [619, 625], [626, 632], [633, 637], [638, 639], [639, 642], [642, 645], [646, 648], [649, 653], [653, 654], [656, 658], [659, 663], [664, 666], [667, 676], [676, 677], [679, 680], [681, 685], [686, 690], [691, 696], [696, 697], [699, 700], [701, 703], [704, 709], [710, 711], [712, 715], [716, 719], [720, 724], [725, 727], [728, 734], [735, 738], [739, 741], [742, 744], [745, 747], [748, 753], [754, 756], [757, 760], [760, 763], [764, 766], [767, 769], [770, 772], [773, 777], [777, 778], [780, 784], [785, 788], [789, 790], [791, 796], [797, 801], [802, 807], [808, 811], [812, 814], [815, 821], [822, 826], [827, 828], [829, 831], [832, 835], [835, 836], [838, 841], [842, 849], [850, 854], [855, 858], [859, 862], [863, 865], [866, 873], [874, 876], [877, 881], [882, 884], [885, 889], [890, 897], [898, 901], [902, 905], [906, 910], [911, 917], [917, 918], [920, 923], [924, 931], [932, 936], [937, 940], [941, 944], [945, 949], [950, 956], [957, 959], [960, 962], [963, 971], [971, 972], [974, 975], [975, 976], [976, 977], [978, 981], [982, 983], [984, 987], [987, 988], [988, 989], [989, 990], [990, 991], [991, 992], [992, 993], [995, 999], [1000, 1002], [1003, 1006], [1007, 1015], [1015, 1016], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0]]}\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a0d89e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\", evaluation_strategy=\"epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47e90662",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "metric = load_metric(\"accuracy\")\n",
    "def compute_metrics(eval_pred):\n",
    "    print(eval_pred, eval_pred.shape)\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46d291ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97089f6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: events, entities, coreferences, document_id, offset_mapping, text, id, relations, passages. If events, entities, coreferences, document_id, offset_mapping, text, id, relations, passages are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "C:\\Users\\richa\\Documents\\GitHub\\transformers-interpret\\.env\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 625\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 237\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='237' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  3/237 01:03 < 4:09:00, 0.02 it/s, Epoch 0.03/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10896\\4032920361.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\GitHub\\transformers-interpret\\.env\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1407\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inner_training_loop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_batch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_find_batch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1408\u001b[0m         )\n\u001b[1;32m-> 1409\u001b[1;33m         return inner_training_loop(\n\u001b[0m\u001b[0;32m   1410\u001b[0m             \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\transformers-interpret\\.env\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1649\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1650\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1651\u001b[1;33m                     \u001b[0mtr_loss_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1652\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1653\u001b[0m                 if (\n",
      "\u001b[1;32m~\\Documents\\GitHub\\transformers-interpret\\.env\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[1;34m(self, model, inputs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeepspeed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\transformers-interpret\\.env\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 363\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\transformers-interpret\\.env\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[1;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m     \u001b[1;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf74b7b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in trained_models/cadec_bigbio_kb_2022-07-08 17_50_33.139013\\config.json\n",
      "Model weights saved in trained_models/cadec_bigbio_kb_2022-07-08 17_50_33.139013\\pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "import os, datetime\n",
    "os.makedirs(f\"trained_models\", exist_ok=True)\n",
    "model.save_pretrained(f\"trained_models/{dataset_name}_{str(datetime.datetime.now()).replace(':', '_')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ef00f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
